{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb8d42b-3348-42b9-80a0-456d68cbc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28145f77-5c92-4e74-a5e3-a8e6141310dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " from europarl_preprocessing import write_new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c079212-525e-4b4d-b28f-4b1cfea0f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsz = 500000\n",
    "vate_size = int(tsz/4)\n",
    "write_new_files(tsz, vate_size, vate_size, max_sentence_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c60ef3b-b37e-4fb7-bf68-a247d6cefe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n",
      "473402\n"
     ]
    }
   ],
   "source": [
    "def get_number_lines(path):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return len(lines)        \n",
    "\n",
    "path = os.path.join('europarl','train_sentences.txt')\n",
    "coco_path = os.path.join('coco','train_sentences.txt')\n",
    "europarl_train = get_number_lines(path)\n",
    "coco_train = get_number_lines(coco_path)\n",
    "print(europarl_train)\n",
    "print(coco_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8a8db8-adc0-4b1e-ac4a-f65da39b8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "directory = 'europarl'\n",
    "\n",
    "def regexification(sentences):\n",
    "    regex = [r\"[^A-Za-z0-9]+|[a-zA-Z][0-9]\", r\"(?<!\\d)[0]\\d*(?!\\d)\", r\"\\s+\", r\"[0-9]+\"]\n",
    "    for r in regex:\n",
    "        sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), sentences))\n",
    "    return sentences\n",
    "\n",
    "def get_files_paths(directory):\n",
    "    train_txt = 'train_sentences.txt'    \n",
    "    valid_txt = 'valid_sentences.txt'\n",
    "    test_txt = 'test_sentences.txt'\n",
    "    train_path = os.path.join(directory,train_txt)    \n",
    "    valid_path = os.path.join(directory,valid_txt)\n",
    "    test_path = os.path.join(directory,test_txt)\n",
    "    return train_path, valid_path, test_path\n",
    "\n",
    "def get_sentences_from_file(filename):\n",
    "    sentences = []\n",
    "    with open(filename, mode='rt', encoding='utf-8') as file_object:\n",
    "        for line in file_object:\n",
    "            sentences.append(line)    \n",
    "    return sentences\n",
    "\n",
    "def get_clip_embeddings(sentences, batch_size=32):\n",
    "    tokenized_text = clip.tokenize(sentences).to(device)\n",
    "    with torch.no_grad():\n",
    "        clip_embeddings_list = []\n",
    "        for i in range(0,tokenized_text.size()[0],batch_size):\n",
    "            tok_batch = tokenized_text[i:i+batch_size]\n",
    "            clip_embeddings_batch = clip_model.encode_text(tok_batch).to(device)\n",
    "            for unity in clip_embeddings_batch:\n",
    "                clip_embeddings_list.append(unity)\n",
    "    final_emb = torch.stack(clip_embeddings_list)\n",
    "    return final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd9d89-a9e1-4b23-9846-ea28101a7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file, valid_file, test_file = get_files_paths(directory)\n",
    "train_len = get_number_lines(train_file)\n",
    "valid_len = get_number_lines(valid_file)\n",
    "test_len = get_number_lines(test_file)\n",
    "print([train_len, valid_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb73be3-cc21-459f-9584-55d415c5e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc686b-e05f-4773-98c0-eac3070b8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = regexification(get_sentences_from_file(train_file))\n",
    "valid_sentences = regexification(get_sentences_from_file(valid_file))\n",
    "train_clip_embeddings = get_clip_embeddings(train_sentences)\n",
    "valid_clip_embeddings = get_clip_embeddings(valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c17194-8c75-4e77-a12c-e966f7165fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sentence(sentence, length=5):\n",
    "    new_sentences = []\n",
    "    splitted = sentence.split()\n",
    "    N = len(splitted)\n",
    "    if  N < length:\n",
    "        new_sentences.append(sentence)\n",
    "        return new_sentences\n",
    "    \n",
    "    result = \"\"\n",
    "    for i in range(length):\n",
    "        result += splitted[i] + \" \"\n",
    "    result = result[:-1]\n",
    "    new_sentences.append(result)\n",
    "                         \n",
    "    rest = \"\"\n",
    "    for i in range(length,N):\n",
    "        rest += splitted[i] + \" \"\n",
    "    rest = rest[:-1]\n",
    "    other_sentences = truncate_sentence(rest)\n",
    "    for os in other_sentences:\n",
    "        new_sentences.append(os)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c150ec-e401-4726-b46f-012726042e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esta es una frase muy', 'larga, puede estar en cualquier', 'idioma y no necesita realmente', 'tener algún sentido']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Esta es una frase muy larga, puede estar en cualquier idioma y no necesita realmente tener algún sentido\"\n",
    "ns = truncate_sentence(sentence)\n",
    "print(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828e17d6-6773-4e72-b603-42cb6dd0fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_long_embeddings(sentences, batch_size=32):\n",
    "    clip_embeddings_list = []\n",
    "    for sentence in sentences:\n",
    "        short_sentences = truncate_sentence(sentence)\n",
    "        tokenized_text = clip.tokenize(short_sentences).to(device)\n",
    "        with torch.no_grad():            \n",
    "            clip_embeddings_sentences = clip_model.encode_text(tokenized_text).to(device)\n",
    "            clip_embeddings = torch.mean(clip_embeddings_sentences,0)\n",
    "            clip_embeddings_list.append(clip_embeddings)\n",
    "    final_emb = torch.stack(clip_embeddings_list)\n",
    "    return final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1798d365-5fd9-44a2-ae55-053e6fca29b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Estas todas son frases sin sentido que necesitamos para alimentar al mounstruo de CLIP\", \"Maybe I should speak english, so the CLIP embeddings can understand\", \n",
    "             \"After all, this is his preferred language\", \"And I shouldnt exceed the 77 tokens. LOL.\"]\n",
    "embs_long = get_clip_long_embeddings(sentences)\n",
    "print(\"Size: {}\".format(embs_long.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0254b24e-fbc0-4442-afa6-d17ea96ae91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "embs = get_clip_embeddings(sentences)\n",
    "print(\"Size: {}\".format(embs.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f8cfe98-e8e7-4b23-ac23-b6d7e0a2ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0dc9e8c-885d-476f-a8db-b3a3055cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_interior(file):\n",
    "    directory = 'coco/annotations'\n",
    "    f_val = open(os.path.join(directory,file))\n",
    "    val_data = json.load(f_val)\n",
    "    for e in val_data:\n",
    "        print(e)\n",
    "    images = val_data['images']\n",
    "    annotations = val_data['annotations']\n",
    "    print(len(images))\n",
    "    print(len(annotations))\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b0b28d0-e3f6-4161-ac3e-97e647b45788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "5000\n",
      "25014\n"
     ]
    }
   ],
   "source": [
    "cap_img, cap_ann = show_interior('captions_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "824fb294-d456-4429-aafc-45b949cae6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "categories\n",
      "5000\n",
      "36781\n"
     ]
    }
   ],
   "source": [
    "ins_img, ins_ann =show_interior('instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad04471c-333a-4c52-8cc2-d39f8c620a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "categories\n",
      "5000\n",
      "11004\n"
     ]
    }
   ],
   "source": [
    "per_img, per_ann = show_interior('person_keypoints_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35f8fcb7-9720-49ae-8398-29e3a3af0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "source_dirs = ['europarl','coco']\n",
    "train_sizes = [1000,2000]\n",
    "number_epochs = [50]\n",
    "with open(\"preprocessing/config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e37d461f-4a8c-4e7e-b6ed-81f8950cc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl\n",
      "spanish_europarl\n",
      "coco\n",
      "test\n",
      "languages\n"
     ]
    }
   ],
   "source": [
    "for element in cfg:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b615f0-5e05-4adc-bccd-63c7c4d38bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsz in train_sizes:\n",
    "    val_test_size = int(tsz/4)\n",
    "    for i, train_dir in enumerate(source_dirs):\n",
    "        params = cfg[train_dir]\n",
    "        data_dir = params['data_dir']\n",
    "        out_dir = params['out_dir']        \n",
    "        try:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
