{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb8d42b-3348-42b9-80a0-456d68cbc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from experiment import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28145f77-5c92-4e74-a5e3-a8e6141310dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " from europarl_preprocessing import write_new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c079212-525e-4b4d-b28f-4b1cfea0f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsz = 500000\n",
    "vate_size = int(tsz/4)\n",
    "write_new_files(tsz, vate_size, vate_size, max_sentence_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c60ef3b-b37e-4fb7-bf68-a247d6cefe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_lines(path):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4396c382-6896-4be9-9765-8c00d9ccbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('gcc','train_sentences.txt')\n",
    "coco_path = os.path.join('coco','train_sentences.txt')\n",
    "europarl_train = get_number_lines(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17633b9a-f50e-4845-adae-9c18907d98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2654581\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('gcc','big_train_file.txt')\n",
    "train_size = get_number_lines(path)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088078ad-a80f-4fbc-81fe-08b622d72305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331799\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('gcc','big_test_file.txt')\n",
    "train_size = get_number_lines(path)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91988075-d3f3-48dd-a2ca-b4cb75a748b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331768\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('gcc','big_valid_file.txt')\n",
    "train_size = get_number_lines(path)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a64b1-1b2e-4375-bcba-4f141eabe978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d6635e-2cea-4212-bcd5-c257b20c5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['Margarita-Bugueno.jpg', 'tree.jpeg', 'poodle.jpg','flower.jpg']\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72228cc-50c3-4996-b509-bd9a7c6d142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(images, clip_model, preprocess):\n",
    "    N = len(images)\n",
    "    count = 0\n",
    "    image_features = torch.empty(size=(N, 512))\n",
    "    for i,image_id in enumerate(images):\n",
    "        count += 1\n",
    "        im = Image.open(image_id)        \n",
    "        image = preprocess(im).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            clip_image = clip_model.encode_image(image)\n",
    "            image_features[i] = clip_image\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67288cd-8787-4940-81d0-7d8a0424b0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_features = get_images(images,clip_model,preprocess)\n",
    "images_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1258c4cc-0ecc-43c8-955f-f440763c9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\"A cute little dog\", \"Un perrito bonito\", \"Uroczy, mały piesek\", \n",
    "            \"Un petit chien mignon\", \"Ein süßer kleiner Hund\", \"Un piccolo cane carino\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3351f501-e63f-4630-990f-3946045c655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\"A yellow flower\",\"Una flor amarilla\",\"Zolty Kwiatek\",\"Une fleur jaune\", \"Eine gelbe Blume\",\"un fiore giallo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b851e1-1c74-47ca-80a1-a8c3b7f21d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_features = get_clip_embeddings(captions,clip_model).to(device)\n",
    "clip_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09ad05d0-0bda-4017-96fe-1c06e8d79bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A yellow flower\n",
      "[0.11420055 0.10807043 0.07017227 0.70755666]\n",
      "Una flor amarilla\n",
      "[0.19993378 0.0851327  0.12104443 0.5938891 ]\n",
      "Zolty Kwiatek\n",
      "[0.31335264 0.18450633 0.19757947 0.30456156]\n",
      "Une fleur jaune\n",
      "[0.17498663 0.12924773 0.08789355 0.60787207]\n",
      "Eine gelbe Blume\n",
      "[0.15191233 0.15184061 0.11434212 0.58190495]\n",
      "un fiore giallo\n",
      "[0.1557688  0.13171895 0.09323486 0.6192774 ]\n"
     ]
    }
   ],
   "source": [
    "for i, clip_feature in enumerate(clip_features):\n",
    "    print(captions[i])\n",
    "    logits_image_clip, logits_text_clip = get_logits(images_features, clip_feature)\n",
    "    probs_clip = logits_image_clip.softmax(dim=-1).to('cpu').detach().numpy()\n",
    "    print(probs_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720f8de1-41b4-4b20-99b3-4302c700a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment import sbert_to_clip\n",
    "sbert_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "torch_features = get_sbert_embeddings(captions,sbert_model) \n",
    "torch_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae100e5-9cf9-4606-bb37-68fe1590c7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_features = sbert_to_clip(torch_features,'gcc_NN_750_e300_s2654581.pt')\n",
    "sbert_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d696dad-7dc6-4ccc-a305-333adb5b3673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dd0e9f-69e0-4e42-8179-573d0561aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A yellow flower\n",
      "[0.25561073 0.17334817 0.11221261 0.45882848]\n",
      "Una flor amarilla\n",
      "[0.26155874 0.17659798 0.11643499 0.4454083 ]\n",
      "Zolty Kwiatek\n",
      "[0.24662964 0.17836365 0.12518138 0.44982538]\n",
      "Une fleur jaune\n",
      "[0.2529453  0.17863216 0.11457665 0.4538458 ]\n",
      "Eine gelbe Blume\n",
      "[0.27591568 0.16273409 0.12072165 0.44062856]\n",
      "un fiore giallo\n",
      "[0.2499876  0.18935394 0.12197234 0.4386862 ]\n"
     ]
    }
   ],
   "source": [
    "for i, sbert_feature in enumerate(sbert_features):\n",
    "    print(captions[i])\n",
    "    logits_image_sbert, logits_text_sbert = get_logits(images_features, sbert_feature)\n",
    "    probs_sbert = logits_image_sbert.softmax(dim=-1).to('cpu').detach().numpy()\n",
    "    print(probs_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8add1586-8067-4bf4-b736-333f139a36b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margarita-Bugueno.jpg\n",
      "[0.6583897  0.1578371  0.18377325]\n",
      "tree.jpeg\n",
      "[0.14538383 0.6917188  0.16289736]\n",
      "poodle.jpg\n",
      "[0.24891849 0.14688429 0.60419714]\n"
     ]
    }
   ],
   "source": [
    "for i, im_feature in enumerate(images_features):\n",
    "    print(captions[i])\n",
    "    logits_image_clip, logits_text_clip = get_logits(im_feature, clip_features)\n",
    "    probs_clip = logits_image_clip.softmax(dim=-1).to('cpu').detach().numpy()\n",
    "    print(probs_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8a8db8-adc0-4b1e-ac4a-f65da39b8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "directory = 'europarl'\n",
    "\n",
    "def regexification(sentences):\n",
    "    regex = [r\"[^A-Za-z0-9]+|[a-zA-Z][0-9]\", r\"(?<!\\d)[0]\\d*(?!\\d)\", r\"\\s+\", r\"[0-9]+\"]\n",
    "    for r in regex:\n",
    "        sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), sentences))\n",
    "    return sentences\n",
    "\n",
    "def get_files_paths(directory):\n",
    "    train_txt = 'train_sentences.txt'    \n",
    "    valid_txt = 'valid_sentences.txt'\n",
    "    test_txt = 'test_sentences.txt'\n",
    "    train_path = os.path.join(directory,train_txt)    \n",
    "    valid_path = os.path.join(directory,valid_txt)\n",
    "    test_path = os.path.join(directory,test_txt)\n",
    "    return train_path, valid_path, test_path\n",
    "\n",
    "def get_sentences_from_file(filename):\n",
    "    sentences = []\n",
    "    with open(filename, mode='rt', encoding='utf-8') as file_object:\n",
    "        for line in file_object:\n",
    "            sentences.append(line)    \n",
    "    return sentences\n",
    "\n",
    "def get_clip_embeddings(sentences, batch_size=32):\n",
    "    tokenized_text = clip.tokenize(sentences).to(device)\n",
    "    with torch.no_grad():\n",
    "        clip_embeddings_list = []\n",
    "        for i in range(0,tokenized_text.size()[0],batch_size):\n",
    "            tok_batch = tokenized_text[i:i+batch_size]\n",
    "            clip_embeddings_batch = clip_model.encode_text(tok_batch).to(device)\n",
    "            for unity in clip_embeddings_batch:\n",
    "                clip_embeddings_list.append(unity)\n",
    "    final_emb = torch.stack(clip_embeddings_list)\n",
    "    return final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd9d89-a9e1-4b23-9846-ea28101a7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file, valid_file, test_file = get_files_paths(directory)\n",
    "train_len = get_number_lines(train_file)\n",
    "valid_len = get_number_lines(valid_file)\n",
    "test_len = get_number_lines(test_file)\n",
    "print([train_len, valid_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb73be3-cc21-459f-9584-55d415c5e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc686b-e05f-4773-98c0-eac3070b8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = regexification(get_sentences_from_file(train_file))\n",
    "valid_sentences = regexification(get_sentences_from_file(valid_file))\n",
    "train_clip_embeddings = get_clip_embeddings(train_sentences)\n",
    "valid_clip_embeddings = get_clip_embeddings(valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c17194-8c75-4e77-a12c-e966f7165fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sentence(sentence, length=5):\n",
    "    new_sentences = []\n",
    "    splitted = sentence.split()\n",
    "    N = len(splitted)\n",
    "    if  N < length:\n",
    "        new_sentences.append(sentence)\n",
    "        return new_sentences\n",
    "    \n",
    "    result = \"\"\n",
    "    for i in range(length):\n",
    "        result += splitted[i] + \" \"\n",
    "    result = result[:-1]\n",
    "    new_sentences.append(result)\n",
    "                         \n",
    "    rest = \"\"\n",
    "    for i in range(length,N):\n",
    "        rest += splitted[i] + \" \"\n",
    "    rest = rest[:-1]\n",
    "    other_sentences = truncate_sentence(rest)\n",
    "    for os in other_sentences:\n",
    "        new_sentences.append(os)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c150ec-e401-4726-b46f-012726042e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esta es una frase muy', 'larga, puede estar en cualquier', 'idioma y no necesita realmente', 'tener algún sentido']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Esta es una frase muy larga, puede estar en cualquier idioma y no necesita realmente tener algún sentido\"\n",
    "ns = truncate_sentence(sentence)\n",
    "print(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828e17d6-6773-4e72-b603-42cb6dd0fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_long_embeddings(sentences, batch_size=32):\n",
    "    clip_embeddings_list = []\n",
    "    for sentence in sentences:\n",
    "        short_sentences = truncate_sentence(sentence)\n",
    "        tokenized_text = clip.tokenize(short_sentences).to(device)\n",
    "        with torch.no_grad():            \n",
    "            clip_embeddings_sentences = clip_model.encode_text(tokenized_text).to(device)\n",
    "            clip_embeddings = torch.mean(clip_embeddings_sentences,0)\n",
    "            clip_embeddings_list.append(clip_embeddings)\n",
    "    final_emb = torch.stack(clip_embeddings_list)\n",
    "    return final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1798d365-5fd9-44a2-ae55-053e6fca29b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Estas todas son frases sin sentido que necesitamos para alimentar al mounstruo de CLIP\", \"Maybe I should speak english, so the CLIP embeddings can understand\", \n",
    "             \"After all, this is his preferred language\", \"And I shouldnt exceed the 77 tokens. LOL.\"]\n",
    "embs_long = get_clip_long_embeddings(sentences)\n",
    "print(\"Size: {}\".format(embs_long.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0254b24e-fbc0-4442-afa6-d17ea96ae91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "embs = get_clip_embeddings(sentences)\n",
    "print(\"Size: {}\".format(embs.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f8cfe98-e8e7-4b23-ac23-b6d7e0a2ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0dc9e8c-885d-476f-a8db-b3a3055cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_interior(file):\n",
    "    directory = 'coco/annotations'\n",
    "    f_val = open(os.path.join(directory,file))\n",
    "    val_data = json.load(f_val)\n",
    "    for e in val_data:\n",
    "        print(e)\n",
    "    images = val_data['images']\n",
    "    annotations = val_data['annotations']\n",
    "    print(len(images))\n",
    "    print(len(annotations))\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b0b28d0-e3f6-4161-ac3e-97e647b45788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "5000\n",
      "25014\n"
     ]
    }
   ],
   "source": [
    "cap_img, cap_ann = show_interior('captions_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "824fb294-d456-4429-aafc-45b949cae6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "categories\n",
      "5000\n",
      "36781\n"
     ]
    }
   ],
   "source": [
    "ins_img, ins_ann =show_interior('instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad04471c-333a-4c52-8cc2-d39f8c620a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "licenses\n",
      "images\n",
      "annotations\n",
      "categories\n",
      "5000\n",
      "11004\n"
     ]
    }
   ],
   "source": [
    "per_img, per_ann = show_interior('person_keypoints_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35f8fcb7-9720-49ae-8398-29e3a3af0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "source_dirs = ['europarl','coco']\n",
    "train_sizes = [1000,2000]\n",
    "number_epochs = [50]\n",
    "with open(\"preprocessing/config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e37d461f-4a8c-4e7e-b6ed-81f8950cc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl\n",
      "spanish_europarl\n",
      "coco\n",
      "test\n",
      "languages\n"
     ]
    }
   ],
   "source": [
    "for element in cfg:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b615f0-5e05-4adc-bccd-63c7c4d38bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsz in train_sizes:\n",
    "    val_test_size = int(tsz/4)\n",
    "    for i, train_dir in enumerate(source_dirs):\n",
    "        params = cfg[train_dir]\n",
    "        data_dir = params['data_dir']\n",
    "        out_dir = params['out_dir']        \n",
    "        try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5e413d-55c6-42f4-8c17-4ff9e4c9041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import get_sbert_embeddings, get_images_and_captions, get_sbert_embeddings, sbert_to_clip\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0311859-2cc1-4b7c-8cdd-fc4549421bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31448dc-8c1c-4ad0-81d1-b0c8600122ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {'english':'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78e7f17-8084-4683-835a-6f7cbda7288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, captions = get_images_and_captions(\"crossmodal\",languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "169dcd4d-7d76-4413-86c0-bfa7eded518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_features = get_sbert_embeddings(captions['english'],sbert_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f24e0a6-99eb-4278-9026-ca1bc2506afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_features = sbert_to_clip(torch_features,'gco_NN3_1000_e300_s3127982.pt').type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d76271c1-58b7-47bd-ab76-c0f8cc304c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from multilingual_clip import pt_multilingual_clip\n",
    "import transformers\n",
    "\n",
    "sbert_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "print(\"SBERT model loaded\")\n",
    "mclip_model = pt_multilingual_clip.MultilingualCLIP.from_pretrained('M-CLIP/XLM-Roberta-Large-Vit-B-32')\n",
    "mclip_tokenizer = transformers.AutoTokenizer.from_pretrained('M-CLIP/XLM-Roberta-Large-Vit-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a04fb3e-89d3-464c-8ad8-f4c290c50fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 512, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92e009ed-184b-425a-bf3b-6c927d698fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of MultilingualCLIP(\n",
       "  (transformer): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): XLMRobertaPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (LinearTransformation): Linear(in_features=1024, out_features=512, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclip_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064e159-064a-4cd3-84fa-1143ea0fef7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
