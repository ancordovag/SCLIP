{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee3c53e-2acd-453f-98d1-2427da22bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "#from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"bertin-project/bertin-gpt-j-6B\")\n",
    "model = SentenceTransformer('hackathon-pln-es/bertin-roberta-base-finetuning-esnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd378a8-8068-41cf-9477-94fa42aedb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Well, this are a couple of sentences\", \"that I would like to tokenize\", \"and encode, of course\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a727d3da-1482-4b57-ba8b-1e34384066fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 514, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertin_model = SentenceTransformer('hackathon-pln-es/bertin-roberta-base-finetuning-esnli')\n",
    "bertin_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fa3165-ef85-4ecf-a696-300c51d3c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertin_embeddings(sentences):\n",
    "    with torch.no_grad():  \n",
    "        bertin_embeddings = torch.from_numpy(bertin_model.encode(sentences))\n",
    "    return bertin_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b6c1da-1a02-4e38-8e14-abb0939b0623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6915, -0.6032, -0.4391,  ..., -0.0385, -1.5752, -0.8103],\n",
       "        [-0.2651, -0.5532, -2.0290,  ..., -0.0282, -0.2088, -0.2065],\n",
       "        [ 0.3799, -1.1596,  0.3494,  ...,  0.3747, -0.8787, -1.0959]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bertin_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d7c8a-d0ac-4f6f-af92-e8c3caf960b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_embeddings(sentences):\n",
    "    with torch.no_grad():  \n",
    "        sbert_embeddings = torch.from_numpy(sbert_model.encode(sentences))\n",
    "    return sbert_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
