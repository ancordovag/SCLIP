{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42ba9d-751c-4975-bc5c-62bad713aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import clip\n",
    "import re\n",
    "import time\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from networks import SCLIPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24e302-a481-4e62-9397-ffa4b9cd0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Loading Models\")\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "sbert_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93fd16-5b38-4b55-80aa-4e82e101e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "dirname = cfg[\"dataset\"][\"dirname\"]\n",
    "train_path = 'train_sentences.txt'\n",
    "test_path = 'test_sentences.txt'\n",
    "valid_path = 'valid_sentences.txt'\n",
    "train_filename = dirname + '/' + train_path\n",
    "test_filename = dirname + '/' + test_path\n",
    "valid_filename = dirname + '/' + valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a839d-38af-49c3-b208-912b612a8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "with open(train_filename, mode='rt', encoding='utf-8') as file_object:\n",
    "    for line in file_object:\n",
    "        train_sentences.append(line)\n",
    "N = len(train_sentences)\n",
    "print(\"Number of sentences to train: {}\".format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809181f-02f0-45ce-8ed8-5357c1acf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentences = []\n",
    "with open(valid_filename, mode='rt', encoding='utf-8') as file_object:\n",
    "    for line in file_object:\n",
    "        valid_sentences.append(line)\n",
    "N = len(valid_sentences)\n",
    "print(\"Number of sentences to valid: {}\".format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8a171-7c2c-4a6a-abe4-fb4fbe1bf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "with open(test_filename, mode='rt', encoding='utf-8') as file_object:\n",
    "    for line in file_object:\n",
    "        test_sentences.append(line)\n",
    "N = len(test_sentences)\n",
    "print(\"Number of sentences to test: {}\".format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f210b9a-beb3-47e4-8016-a18151323c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = [r\"[^A-Za-z0-9]+|[a-zA-Z][0-9]\", r\"(?<!\\d)[0]\\d*(?!\\d)\", r\"\\s+\", r\"[0-9]+\"]\n",
    "for r in regex:\n",
    "    train_sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), train_sentences))\n",
    "    valid_sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), valid_sentences))\n",
    "    test_sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), test_sentences))\n",
    "train_text = clip.tokenize(train_sentences).to(device)\n",
    "valid_text = clip.tokenize(valid_sentences).to(device)\n",
    "test_text = clip.tokenize(test_sentences).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8e914-8227-4488-8ad5-247b7fd36a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CLIP encoding...\")\n",
    "with torch.no_grad():\n",
    "    train_clip_embeddings = clip_model.encode_text(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e12f1-5639-4e8a-baec-e8952c25b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    valid_clip_embeddings = clip_model.encode_text(valid_text)\n",
    "    test_clip_embeddings = clip_model.encode_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ba751-3476-4350-8682-a956aa9e6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SBERT encoding...\")\n",
    "with torch.no_grad():  \n",
    "    train_sbert_embeddings = torch.from_numpy(sbert_model.encode(train_sentences))\n",
    "    valid_sbert_embeddings = torch.from_numpy(sbert_model.encode(valid_sentences))\n",
    "    test_sbert_embeddings = torch.from_numpy(sbert_model.encode(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731b50f-53f9-4521-b8b8-6f9ae942faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*10)\n",
    "for sentence, train_clip_embedding, train_sbert_embedding in zip(train_sentences[:1], train_clip_embeddings[:1], train_sbert_embeddings[:1]):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    input_size = train_sbert_embedding.size()[0]    \n",
    "    print(\"Sbert Embedding: \", input_size)\n",
    "    print(\"Clip Embedding: \", train_clip_embedding.size()[0])\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f322cf9-809e-4e5f-8fda-50ba9ccecbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Models to train...\")\n",
    "model = SCLIPNN(input_size, 850).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa86bf-b424-4408-983c-7aedb9ae5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cfg[\"training\"]\n",
    "\n",
    "def train(model, train_sbert_embeddings, train_clip_embeddings, test_sbert_embeddings, test_clip_embeddings,\n",
    "          valid_sbert_embeddings, valid_clip_embeddings, epochs=params[\"epochs\"], print_every=params[\"print_every\"]):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)    \n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels in zip(train_sbert_embeddings, train_clip_embeddings):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.to(float), labels.to(float))       \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        for inputs, labels in zip(test_sbert_embeddings, test_clip_embeddings):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.to(float), labels.to(float))       \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        for inputs, labels in zip(valid_sbert_embeddings, valid_clip_embeddings):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.to(float), labels.to(float))       \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        if (epoch % print_every == 0) or (epoch == epochs - 1):\n",
    "            print(\"Epoch {}. Loss: {}\".format(epoch, train_loss))\n",
    "    \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbab16-4001-4a2a-91fd-ece377de74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"best_model\"\n",
    "start_time = time.time()\n",
    "print('Training model {}'.format(name))\n",
    "train_loss = train(model, train_sbert_embeddings, train_clip_embeddings, \n",
    "                    test_sbert_embeddings, test_clip_embeddings,\n",
    "                    valid_sbert_embeddings, valid_clip_embeddings)\n",
    "torch.save(model.state_dict(), \"models/best_model.pt\")\n",
    "final_loss = round(train_loss[-1],3)\n",
    "end_time = time.gmtime(time.time() - start_time)\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", end_time)\n",
    "print('Finished Training from model {}. Elapsed time: {}.'.format(name,elapsed_time))\n",
    "print(\"-\"*50)\n",
    "actual_time = time.strftime(\"%Y/%m/%d, %H:%M:%S\", time.gmtime(time.time()))\n",
    "print(\"End of Training Process on {}\".format(actual_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbcae1-747c-47a6-b7fc-a84caf999a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_loss[1:], label = name)\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfebd6-03d8-4316-99b7-ead8969b816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_calculator(targets, predictions):    \n",
    "    cosines = []\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "    for tar, pred in zip(targets, predictions):        \n",
    "        cosine = cos(tar, pred)\n",
    "        cosines.append(cosine.item())\n",
    "    return np.array(cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce245fb-36ea-4f28-9aa2-d69deb7bdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_clip_embeddings, test_sbert_embeddings):\n",
    "    cosines = []\n",
    "    euclideans = []\n",
    "    with torch.no_grad():\n",
    "        sum_cos = 0\n",
    "        count = 0\n",
    "        predictions =[]\n",
    "        for tclip, tsbert in zip(test_clip_embeddings, test_sbert_embeddings):        \n",
    "            tclip = tclip.to(device)\n",
    "            tsbert = tsbert.to(device)\n",
    "            prediction = model(tsbert)\n",
    "            predictions.append(prediction)\n",
    "            sum_cos += np.mean(cosin_calculator(tclip, prediction))\n",
    "            count += 1\n",
    "        cosines.append(round(sum_cos/count,3))\n",
    "        stacked_predictions = torch.stack(predictions)\n",
    "        euclidean = torch.cdist(test_clip_embeddings.to(float), stacked_predictions.to(float))\n",
    "        avg_euclidean = torch.mean(euclidean)\n",
    "        euclideans.append(round(avg_euclidean.item(),3))    \n",
    "    return cosines, euclideans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516f197-1d7e-4240-99b8-ea9906ee6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating...\")\n",
    "start_time = time.time()\n",
    "cosines, euclideans = evaluate(model,test_clip_embeddings, test_sbert_embeddings)\n",
    "end_time = time.gmtime(time.time() - start_time)\n",
    "evaluation_time = time.strftime(\"%H:%M:%S\", end_time)\n",
    "print(\"Evaluation Time: {}\".format(evaluation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba5f93-359d-4bf8-b8ca-051b0467ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Cosin\":cosines, \"Euclidean\":euclideans, \n",
    "        \"TrainTime\":[elapsed_time], \"ValLoss\":[final_loss]}\n",
    "results = pd.DataFrame(data, index=[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282ea2b-e1ce-43f6-83f1-157c7ed5b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df926b07-c443-4770-b864-c71449674adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
