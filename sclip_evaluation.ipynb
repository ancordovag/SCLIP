{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698aae09-c421-46a2-8541-9ae293d94e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import clip\n",
    "import re\n",
    "import time\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from networks import SCLIPNN, SCLIPNN3\n",
    "from utils import EmbeddingsDataset, get_models_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecfd1e1-2662-441e-8f80-8bb8fa6abd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Loading Models\")\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_model.eval()\n",
    "bertin_model = SentenceTransformer('hackathon-pln-es/bertin-roberta-base-finetuning-esnli')\n",
    "bertin_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8d090b-7804-44b1-9a9b-15d4c6528c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_file_path(directory):\n",
    "    test_txt = 'test_sentences.txt'\n",
    "    test_path  = os.path.join(directory, test_txt)\n",
    "    return test_path\n",
    "    \n",
    "def get_sentences_from_file(filename):\n",
    "    sentences = []\n",
    "    with open(filename, mode='rt', encoding='utf-8') as file_object:\n",
    "        for line in file_object:\n",
    "            sentences.append(line)    \n",
    "    return sentences\n",
    "\n",
    "def regexification(sentences):\n",
    "    regex = [r\"[^A-Za-z0-9]+|[a-zA-Z][0-9]\", r\"(?<!\\d)[0]\\d*(?!\\d)\", r\"\\s+\", r\"[0-9]+\"]\n",
    "    for r in regex:\n",
    "        sentences = list(map(lambda sentence: re.sub(r, \" \", sentence), sentences))\n",
    "    return sentences\n",
    "\n",
    "def get_clip_embeddings(sentences):\n",
    "    tokenized_text = clip.tokenize(sentences).to(device)\n",
    "    with torch.no_grad():\n",
    "        clip_embeddings = clip_model.encode_text(tokenized_text)\n",
    "        clip_embeddings.to('cpu')\n",
    "    return clip_embeddings\n",
    "\n",
    "def get_sbert_embeddings(sentences):\n",
    "    with torch.no_grad():  \n",
    "        sbert_embeddings = torch.from_numpy(sbert_model.encode(sentences))\n",
    "    return sbert_embeddings\n",
    "\n",
    "def get_bertin_embeddings(sentences):\n",
    "    with torch.no_grad():  \n",
    "        bertin_embeddings = torch.from_numpy(bertin_model.encode(sentences))\n",
    "    return bertin_embeddings\n",
    "\n",
    "def show_embeddings_return_size(sentences, clip_embeddings, sbert_embeddings):\n",
    "    (\"-\"*10)\n",
    "    for sentence, clip_embedding, sbert_embedding in zip(sentences[:1], clip_embeddings[:1], sbert_embeddings[:1]):\n",
    "        print(\"Sentence:\", sentence)\n",
    "        input_size = sbert_embedding.size()[0]    \n",
    "        print(\"Sbert Embedding: \", input_size)\n",
    "        print(\"Clip Embedding: \", clip_embedding.size()[0])\n",
    "        print(\"-\"*10)\n",
    "    return input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca1c8d8-057b-438e-8763-927a6c227ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_embeddings(directory,transformer):\n",
    "    test_file = get_test_file_path(directory)\n",
    "    test_sentences = regexification(get_sentences_from_file(test_file))\n",
    "    print(\"CLIP encoding...\")\n",
    "    test_clip_embeddings = get_clip_embeddings(test_sentences)\n",
    "    if transformer == 'sbert':\n",
    "        print(\"SBERT encoding...\")\n",
    "        test_sbert_embeddings = get_sbert_embeddings(test_sentences)\n",
    "    elif transformer == 'bertin':\n",
    "        print(\"BERTIN encoding...\")\n",
    "        test_sentences = get_sentences_from_file(test_file)\n",
    "        test_embeddings = get_bertin_embeddings(test_sentences)\n",
    "    return test_clip_embeddings, test_embeddings\n",
    "\n",
    "def get_train_embeddings(directory,transformer = 'sbert'):\n",
    "    train_file, valid_file = get_files_paths(directory)\n",
    "    train_sentences = regexification(get_sentences_from_file(train_file))\n",
    "    valid_sentences = regexification(get_sentences_from_file(valid_file))\n",
    "    print(\"CLIP encoding...\")    \n",
    "    train_clip_embeddings = get_clip_embeddings(train_sentences)\n",
    "    valid_clip_embeddings = get_clip_embeddings(valid_sentences)\n",
    "    if transformer == 'sbert':\n",
    "        print(\"SBERT encoding...\")\n",
    "        train_embeddings = get_sbert_embeddings(train_sentences)\n",
    "        valid_embeddings = get_sbert_embeddings(valid_sentences)\n",
    "    elif transformer == 'bertin':\n",
    "        print(\"BERTIN encoding...\")\n",
    "        train_sentences = get_sentences_from_file(train_file)\n",
    "        valid_sentences = get_sentences_from_file(valid_file)\n",
    "        train_embeddings = get_bertin_embeddings(train_sentences)\n",
    "        valid_embeddings = get_bertin_embeddings(valid_sentences)\n",
    "    else:\n",
    "        print(\"Given transformer is not valid\")\n",
    "    return train_clip_embeddings, valid_clip_embeddings, train_embeddings, valid_embeddings\n",
    "\n",
    "def cosin_calculator(targets, predictions):    \n",
    "    cosines = []\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "    for tar, pred in zip(targets, predictions):        \n",
    "        cosine = cos(tar, pred)\n",
    "        cosines.append(cosine.item())\n",
    "    return np.array(cosines)\n",
    "\n",
    "def evaluate(models, input_size, test_dataset, trainset, transformer = 'sbert'):\n",
    "    cosines = []\n",
    "    euclideans = []\n",
    "    with torch.no_grad():           \n",
    "        for name, model in models.items():\n",
    "            path = os.path.join('models',transformer + '_' + trainset + '_' + name+'.pt')\n",
    "            if 'NN3' in name:\n",
    "                loaded_model = SCLIPNN3(input_size,int(name[-3:])).to(device)\n",
    "            else:\n",
    "                loaded_model = SCLIPNN(input_size,int(name[-3:])).to(device)\n",
    "            loaded_model.load_state_dict(torch.load(path))            \n",
    "            sum_cos = 0\n",
    "            count = 0\n",
    "            predictions =[]\n",
    "            test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "            for inputs, labels in test_loader:     \n",
    "                tclip = labels.to(device)\n",
    "                tsbert = inputs.to(device)\n",
    "                prediction = loaded_model(tsbert)\n",
    "                predictions.append(prediction)\n",
    "                sum_cos += np.mean(cosin_calculator(tclip, prediction))\n",
    "                count += 1\n",
    "            cosines.append(round(sum_cos/count,3))\n",
    "            stacked_predictions = torch.stack(predictions)\n",
    "            euclidean = torch.cdist(test_dataset.Y.to(float), stacked_predictions.to(float))\n",
    "            avg_euclidean = torch.mean(euclidean)\n",
    "            euclideans.append(round(avg_euclidean.item(),3))    \n",
    "    return cosines, euclideans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861987db-f017-44e7-b591-87daccbc893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Evaluating with test dataset europarl_es...\n",
      "CLIP encoding...\n",
      "BERTIN encoding...\n",
      "Creating Models to train...\n",
      "4 models created.\n",
      "...the model trained on europarl_es\n",
      "Evaluation Time: 00:00:01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosin</th>\n",
       "      <th>Euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>europarl_es_NN_700</th>\n",
       "      <td>0.897</td>\n",
       "      <td>5.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europarl_es_NN3_700</th>\n",
       "      <td>0.923</td>\n",
       "      <td>4.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europarl_es_NN_800</th>\n",
       "      <td>0.899</td>\n",
       "      <td>5.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europarl_es_NN3_800</th>\n",
       "      <td>0.924</td>\n",
       "      <td>4.566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cosin  Euclidean\n",
       "europarl_es_NN_700   0.897      5.145\n",
       "europarl_es_NN3_700  0.923      4.581\n",
       "europarl_es_NN_800   0.899      5.105\n",
       "europarl_es_NN3_800  0.924      4.566"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Evaluation\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating...\")\n",
    "directories = ['europarl_es'] #params['test_dataset']\n",
    "model_dict = {}\n",
    "trans = 'bertin'\n",
    "for directory in directories:\n",
    "    print(f'Evaluating with test dataset {directory}...')    \n",
    "    test_clip_emb, test_emb = get_test_embeddings(directory, trans)\n",
    "    input_size = test_emb[0].size()[0]\n",
    "    test_dataset = EmbeddingsDataset(test_emb, test_clip_emb)\n",
    "    for train_directory in directories:\n",
    "        model_dict[train_directory] = get_models_to_train(input_size)\n",
    "        print(f'...the model trained on {train_directory}')\n",
    "        start_time = time.time()       \n",
    "        cosines, euclideans = evaluate(model_dict[train_directory],input_size,test_dataset,trainset=train_directory,transformer = trans)\n",
    "        end_time = time.gmtime(time.time() - start_time)\n",
    "        evaluation_time = time.strftime(\"%H:%M:%S\", end_time)\n",
    "        print(\"Evaluation Time: {}\".format(evaluation_time))\n",
    "        data = {\"Cosin\":cosines, \"Euclidean\":euclideans}\n",
    "        indices = []\n",
    "        for km in model_dict[train_directory].keys():\n",
    "            indices.append(train_directory+'_'+km)        \n",
    "        results = pd.DataFrame(data, index=indices)\n",
    "        display(results)\n",
    "print(\"End of Evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744a291-2096-40de-a474-cdff6fbb04d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
